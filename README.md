# LLLM Playground
## Description
This repository contains a personal UI and tools I created to easily try out local LLMs. For the inference part of the LLM I use `llama.cpp` and for the UI I use `streamlit`.  
I understand that there are already fantastic UIs like `text-generation-webui`, but I wanted to code the background in a way that is more within my understanding.

## TODO List
- [ ] Implement a simple way to add a new LLM

## Libraries
- streamlit>=1.29.0
- plyer>=2.1.0
